{"metadata":{"environment":{"kernel":"conda-env-tensorflow-tensorflow","name":"workbench-notebooks.m113","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/workbench-notebooks:m113"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":51294,"databundleVersionId":7331882,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jeffreyesedo/1st-ribo-note?scriptVersionId=165907255\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/jeffreyesedo/1st-ribo-note?scriptVersionId=151222394\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"markdown","source":"# RNA Science Environment and Libraries","metadata":{}},{"cell_type":"code","source":"# Setting up an RNA Science Environment\n!pip install arnie\n!pip install draw_rna\n!pip install viennarna\n!pip install swifter\n\n# Install EternaFold\n!conda config --set auto_update_conda false\n!conda install -c bioconda eternafold --yes\n# Manually setup EternaFold for Kaggle notebook\n%env ETERNAFOLD_PATH=/opt/conda/bin/eternafold-bin\n%env ETERNAFOLD_PARAMETERS=/opt/conda/lib/eternafold-lib/parameters/EternaFoldParams.v1","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:26:56.796148Z","iopub.execute_input":"2023-12-21T11:26:56.796583Z","iopub.status.idle":"2023-12-21T11:30:53.83452Z","shell.execute_reply.started":"2023-12-21T11:26:56.796549Z","shell.execute_reply":"2023-12-21T11:30:53.833044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport psutil\nimport gc\nimport random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:30:53.837308Z","iopub.execute_input":"2023-12-21T11:30:53.837768Z","iopub.status.idle":"2023-12-21T11:30:54.281368Z","shell.execute_reply.started":"2023-12-21T11:30:53.837728Z","shell.execute_reply":"2023-12-21T11:30:54.280013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import RNA\nfrom arnie.mfe import mfe\nfrom arnie.bpps import bpps\nfrom arnie.free_energy import free_energy\nfrom draw_rna.ipynb_draw import draw_struct","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:30:54.283152Z","iopub.execute_input":"2023-12-21T11:30:54.283643Z","iopub.status.idle":"2023-12-21T11:30:54.315627Z","shell.execute_reply.started":"2023-12-21T11:30:54.283609Z","shell.execute_reply":"2023-12-21T11:30:54.309409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Download and extract datasets for local","metadata":{}},{"cell_type":"code","source":"# ! pip install kaggle\n\n# !mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n\n# !mkdir -p ~/.kaggle/\n\n# !mv kaggle.json ~/.kaggle/\n\n# !chmod 600 ~/.kaggle/kaggle.json","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:30:54.319523Z","iopub.execute_input":"2023-12-21T11:30:54.319924Z","iopub.status.idle":"2023-12-21T11:30:54.325018Z","shell.execute_reply.started":"2023-12-21T11:30:54.319889Z","shell.execute_reply":"2023-12-21T11:30:54.323814Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check file in the competition\n# ! kaggle competitions files stanford-ribonanza-rna-folding","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:30:54.326914Z","iopub.execute_input":"2023-12-21T11:30:54.327368Z","iopub.status.idle":"2023-12-21T11:30:54.335814Z","shell.execute_reply.started":"2023-12-21T11:30:54.327326Z","shell.execute_reply":"2023-12-21T11:30:54.334656Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download Dataset to colab\n# ! kaggle competitions download -c stanford-ribonanza-rna-folding  -f train_data.csv -p /download\n# ! kaggle competitions download -c stanford-ribonanza-rna-folding  -f train_data_QUICK_START.csv -p /download\n# ! kaggle competitions download -c stanford-ribonanza-rna-folding  -f test_sequences.csv -p /download\n# ! kaggle competitions download -c stanford-ribonanza-rna-folding  -f sample_submission.csv -p /download\n# ! kaggle competitions download -c stanford-ribonanza-rna-folding  -f supplementary_silico_predictions -p /download\n# ! kaggle competitions download -c stanford-ribonanza-rna-folding  -f eterna_openknot_metadata -p /download","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:30:54.339507Z","iopub.execute_input":"2023-12-21T11:30:54.339841Z","iopub.status.idle":"2023-12-21T11:30:54.347863Z","shell.execute_reply.started":"2023-12-21T11:30:54.339813Z","shell.execute_reply":"2023-12-21T11:30:54.346784Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Unzip datasets\n# import zipfile\n# import os\n\n# Paths \n# file_paths = ['../sample_submission.csv.zip', \n#               '../test_sequences.csv.zip', \n#               '../train_data_QUICK_START.csv.zip', \n#               '../train_data.csv.zip',\n#              './supplementary_silico_predictions',\n#              './eterna_openknot_metadata']  \n# dest_dir = '../datasets'  \n\n# def unzip_files(file_paths, dest_dir):\n#     for file_path in file_paths:\n#         with zipfile.ZipFile(file_path, 'r') as zip_ref:\n#             zip_ref.extractall(dest_dir)\n\n\n# unzip_files(file_paths, dest_dir)\n","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:30:54.349206Z","iopub.execute_input":"2023-12-21T11:30:54.350272Z","iopub.status.idle":"2023-12-21T11:30:54.361328Z","shell.execute_reply.started":"2023-12-21T11:30:54.350239Z","shell.execute_reply":"2023-12-21T11:30:54.360347Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Datasets","metadata":{}},{"cell_type":"markdown","source":"## train & test data","metadata":{}},{"cell_type":"code","source":"train= pd.read_csv(\"/kaggle/input/stanford-ribonanza-rna-folding/train_data.csv\")\n# train= pd.read_csv(\"/kaggle/input/stanford-ribonanza-rna-folding/train_data_QUICK_START.csv\")\ntest= pd.read_csv(\"/kaggle/input/stanford-ribonanza-rna-folding/test_sequences.csv\")\n\n# train=pd.read_csv('../datasets/train_data.csv')\n# test=pd.read_csv('../datasets/test_sequences.csv')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:30:54.362325Z","iopub.execute_input":"2023-12-21T11:30:54.362698Z","iopub.status.idle":"2023-12-21T11:32:58.068591Z","shell.execute_reply.started":"2023-12-21T11:30:54.362659Z","shell.execute_reply":"2023-12-21T11:32:58.067349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Train dataset shape: {train.shape}\\n\")\n\nprint(f\"Test dataset shape: {test.shape}\")","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:32:58.070545Z","iopub.execute_input":"2023-12-21T11:32:58.071368Z","iopub.status.idle":"2023-12-21T11:32:58.078856Z","shell.execute_reply.started":"2023-12-21T11:32:58.071326Z","shell.execute_reply":"2023-12-21T11:32:58.077449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## optimizing dataset for memory","metadata":{}},{"cell_type":"code","source":"# optimize numeric data types\ndef opt_num(df):\n    df= df.copy()\n    \n    for col in df.columns:\n        df_col= df[col]\n        dn = df_col.dtype.name\n        \n        if dn == \"int64\":\n            df[col]= pd.to_numeric(df_col, downcast=\"integer\")\n        elif dn == \"float64\":\n            df[col]= pd.to_numeric(df_col, downcast=\"float\")\n        elif dn == \"object\":\n            num_unique_values = len(df_col.unique())\n            num_total_values = len(df_col)\n            if num_unique_values / num_total_values < 0.5:\n                df[col] = df_col.astype(\"category\")\n    return df","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:32:58.085315Z","iopub.execute_input":"2023-12-21T11:32:58.085789Z","iopub.status.idle":"2023-12-21T11:32:58.096274Z","shell.execute_reply.started":"2023-12-21T11:32:58.085749Z","shell.execute_reply":"2023-12-21T11:32:58.094796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt_train= opt_num(train)\nopt_test= opt_num(test)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:32:58.098134Z","iopub.execute_input":"2023-12-21T11:32:58.098597Z","iopub.status.idle":"2023-12-21T11:33:29.16273Z","shell.execute_reply.started":"2023-12-21T11:32:58.098554Z","shell.execute_reply":"2023-12-21T11:33:29.161633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Train Dataset:{train.iloc[0:5, 0:10].info()}\\n\")\nprint(f\"Optimized Dataset: {opt_train.iloc[0:5, 0:10].info()}\")","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:33:29.164557Z","iopub.execute_input":"2023-12-21T11:33:29.165354Z","iopub.status.idle":"2023-12-21T11:33:31.103117Z","shell.execute_reply.started":"2023-12-21T11:33:29.165309Z","shell.execute_reply":"2023-12-21T11:33:31.101872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train\ndel test\ngc.collect()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:33:31.104956Z","iopub.execute_input":"2023-12-21T11:33:31.105717Z","iopub.status.idle":"2023-12-21T11:33:31.311564Z","shell.execute_reply.started":"2023-12-21T11:33:31.105681Z","shell.execute_reply":"2023-12-21T11:33:31.310503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Export Dataset as Parquet\n# opt_train.to_parquet('train_data.parquet')\n# opt_test.to_parquet('test_data.parquet')\n\n# Import Parquet Dataset\n# train_df = pd.read_parquet('/kaggle/working/train_data.parquet')\n# train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-21T11:33:31.312762Z","iopub.execute_input":"2023-12-21T11:33:31.313293Z","iopub.status.idle":"2023-12-21T11:33:31.318111Z","shell.execute_reply.started":"2023-12-21T11:33:31.313263Z","shell.execute_reply":"2023-12-21T11:33:31.316904Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## secondary structures data","metadata":{}},{"cell_type":"code","source":"# Import eterna openknot dataset\n# eterna_pos= pd.read_table(\"/kaggle/input/stanford-ribonanza-rna-folding/eterna_openknot_metadata/Positives240-2000.tsv\", sep=\"\\\\t\")\n# eterna_puz_132= pd.read_csv(\"/kaggle/input/stanford-ribonanza-rna-folding/eterna_openknot_metadata/puzzle 12378132.tsv\", sep= \"\\\\t\")\n# eterna_puz_RYOP50= pd.read_csv(\"/kaggle/input/stanford-ribonanza-rna-folding/eterna_openknot_metadata/puzzle_11318423_RYOP50_with_description.tsv\", sep= \"\\\\t\")\n# eterna_puz_RYOP90= pd.read_csv(\"/kaggle/input/stanford-ribonanza-rna-folding/eterna_openknot_metadata/puzzle_11387276_RYOP90_with_description.tsv\", sep= \"\\\\t\")\n# eterna_puz_RFAM= pd.read_csv(\"/kaggle/input/stanford-ribonanza-rna-folding/eterna_openknot_metadata/puzzle_11627601_with_descriptions_PLUS_RFAM.tsv\", sep= \"\\\\t\")\n# eterna_puz_118= pd.read_csv(\"/kaggle/input/stanford-ribonanza-rna-folding/eterna_openknot_metadata/puzzle_11836497_with_description.tsv\", sep= \"\\\\t\")","metadata":{"execution":{"iopub.status.busy":"2023-12-21T11:33:31.319822Z","iopub.execute_input":"2023-12-21T11:33:31.32034Z","iopub.status.idle":"2023-12-21T11:33:31.332078Z","shell.execute_reply.started":"2023-12-21T11:33:31.320299Z","shell.execute_reply":"2023-12-21T11:33:31.330971Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Import Supplementary Silico prediction, that is, secondary structure predictions\n# gpn15k_preds= pd.read_csv(\"/kaggle/input/stanford-ribonanza-rna-folding/supplementary_silico_predictions/GPN15k_silico_predictions.csv\")\n# pk50_preds= pd.read_csv(\"/kaggle/input/stanford-ribonanza-rna-folding/supplementary_silico_predictions/PK50_silico_predictions.csv\")\n# pk90_preds= pd.read_csv(\"/kaggle/input/stanford-ribonanza-rna-folding/supplementary_silico_predictions/PK90_silico_predictions.csv\")\n# r1_preds= pd.read_csv(\"/kaggle/input/stanford-ribonanza-rna-folding/supplementary_silico_predictions/R1_silico_predictions.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-21T11:33:31.33355Z","iopub.execute_input":"2023-12-21T11:33:31.333915Z","iopub.status.idle":"2023-12-21T11:33:31.345027Z","shell.execute_reply.started":"2023-12-21T11:33:31.333884Z","shell.execute_reply":"2023-12-21T11:33:31.343543Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gpn15k_preds.shape\n# gpn15k_preds.head()\n# pk50_preds.shape\n# pk50_preds.head()\n# pk90_preds.shape\n# pk90_preds.head()\n# r1_preds.shape\n# r1_preds.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-21T11:33:31.346378Z","iopub.execute_input":"2023-12-21T11:33:31.347119Z","iopub.status.idle":"2023-12-21T11:33:31.359252Z","shell.execute_reply.started":"2023-12-21T11:33:31.347074Z","shell.execute_reply":"2023-12-21T11:33:31.358166Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration and Visualization","metadata":{}},{"cell_type":"code","source":"opt_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-21T11:33:31.361237Z","iopub.execute_input":"2023-12-21T11:33:31.361624Z","iopub.status.idle":"2023-12-21T11:33:31.404158Z","shell.execute_reply.started":"2023-12-21T11:33:31.361593Z","shell.execute_reply":"2023-12-21T11:33:31.402935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Test Columns: {opt_test.info()}\")","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:33:31.406002Z","iopub.execute_input":"2023-12-21T11:33:31.406941Z","iopub.status.idle":"2023-12-21T11:33:31.716968Z","shell.execute_reply.started":"2023-12-21T11:33:31.406906Z","shell.execute_reply":"2023-12-21T11:33:31.715685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count columns based on their Dtype\n# dtype_counts = opt_train.dtypes.value_counts()\n# print(dtype_counts)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:33:31.718625Z","iopub.execute_input":"2023-12-21T11:33:31.719111Z","iopub.status.idle":"2023-12-21T11:33:31.724821Z","shell.execute_reply.started":"2023-12-21T11:33:31.719067Z","shell.execute_reply":"2023-12-21T11:33:31.723405Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"experiments_count= opt_train[\"experiment_type\"].value_counts()\nprint(experiments_count)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:33:31.726214Z","iopub.execute_input":"2023-12-21T11:33:31.726529Z","iopub.status.idle":"2023-12-21T11:33:31.749235Z","shell.execute_reply.started":"2023-12-21T11:33:31.726503Z","shell.execute_reply":"2023-12-21T11:33:31.747515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing RNA  sequence for DMS MaP\ndms_map= opt_train[opt_train.experiment_type == \"DMS_MaP\"]\nseq_index= random.randint(0,len(dms_map.sequence))\n\nseq_dms = opt_train[opt_train[\"experiment_type\"] == \"DMS_MaP\"].iloc[seq_index, 1:3]\nprint(seq_dms)\n\nstructure = mfe(seq_dms.sequence,package=\"eternafold\")\nprint(structure)\n\nfig, axs = plt.subplots(1,1,  figsize=(8,7))\ndraw_struct(seq_dms.sequence, structure, ax=axs)\naxs.set_title(seq_dms.experiment_type, loc='left', fontsize='medium')\nplt.show()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:33:31.750762Z","iopub.execute_input":"2023-12-21T11:33:31.75121Z","iopub.status.idle":"2023-12-21T11:33:38.605357Z","shell.execute_reply.started":"2023-12-21T11:33:31.751177Z","shell.execute_reply":"2023-12-21T11:33:38.604079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing RNA  sequence for 2A3 MaP\nmap_2a3= opt_train[opt_train.experiment_type == \"2A3_MaP\"]\nseq_index= random.randint(0,len(map_2a3.sequence))\n\nseq_2a3 = opt_train[opt_train[\"experiment_type\"] == \"2A3_MaP\"].iloc[seq_index, 1:3]\nprint(seq_2a3)\n\nstructure = mfe(seq_2a3.sequence,package=\"eternafold\")\nprint(structure)\n\nfig, axs = plt.subplots(1,1,  figsize=(8,7))\ndraw_struct(seq_2a3.sequence, structure, ax=axs)\naxs.set_title(seq_2a3.experiment_type, loc='left', fontsize='medium')\nplt.show()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:33:38.607156Z","iopub.execute_input":"2023-12-21T11:33:38.608116Z","iopub.status.idle":"2023-12-21T11:33:47.965418Z","shell.execute_reply.started":"2023-12-21T11:33:38.608068Z","shell.execute_reply":"2023-12-21T11:33:47.964344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq_len= opt_train.sequence.apply(len)\nseq_len = seq_len.value_counts()\n# seq_len = pd.Series(seq_len)\n# seq_len\n\nseq_len.plot.bar()\nplt.xlabel(\"Sequences Lenght\")\nplt.title(\"Sequence lenght Distribution\")","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:33:47.966786Z","iopub.execute_input":"2023-12-21T11:33:47.967145Z","iopub.status.idle":"2023-12-21T11:33:48.964237Z","shell.execute_reply.started":"2023-12-21T11:33:47.967106Z","shell.execute_reply":"2023-12-21T11:33:48.962814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq_test_len= opt_test.sequence.apply(len)\nseq_test_len = seq_test_len.value_counts()\n# seq_len = pd.Series(seq_len)\n# seq_len\n\nseq_test_len.plot.bar()\nplt.xlabel(\"Sequences Lenght\")\nplt.title(\"Test Sequence lenght Distribution\")","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:33:48.965837Z","iopub.execute_input":"2023-12-21T11:33:48.966247Z","iopub.status.idle":"2023-12-21T11:33:50.090659Z","shell.execute_reply.started":"2023-12-21T11:33:48.96621Z","shell.execute_reply":"2023-12-21T11:33:50.089457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"lengths of RNA sequence is between 115 to 206, while for the test the lengths are between 177 to 457.  Part of the challenge is to know whether the patterns recognized at length 115 to 206 will generalize to longer lengths [response found here.](https://www.kaggle.com/competitions/stanford-ribonanza-rna-folding/discussion/453147#2513582).","metadata":{}},{"cell_type":"code","source":"base= {\"A\": 0,\"C\":0,\"G\":0,\"U\":0}\n\nfor seq in opt_train.sequence:\n    for base_key in base.keys():\n        base[base_key] += seq.count(base_key)\n\n\nplt.bar(base.keys(), base.values())\nplt.xlabel('Base', fontsize = 12, fontweight = 'bold', color = 'darkblue')\nplt.ylabel('Count', fontsize = 12, fontweight = 'bold', color = 'darkblue')\nplt.title('Base Count', fontsize = 14, fontweight = 'bold', color = 'darkgreen')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:33:50.092626Z","iopub.execute_input":"2023-12-21T11:33:50.0934Z","iopub.status.idle":"2023-12-21T11:33:58.224126Z","shell.execute_reply.started":"2023-12-21T11:33:50.093355Z","shell.execute_reply":"2023-12-21T11:33:58.222855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del seq_dms\ndel seq_2a3\ndel map_2a3\ndel dms_map\ndel seq_test_len\ndel seq_len\ngc.collect()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:33:58.226058Z","iopub.execute_input":"2023-12-21T11:33:58.226622Z","iopub.status.idle":"2023-12-21T11:33:58.361045Z","shell.execute_reply.started":"2023-12-21T11:33:58.226577Z","shell.execute_reply":"2023-12-21T11:33:58.359491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt_train.reads.describe()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:33:58.369956Z","iopub.execute_input":"2023-12-21T11:33:58.370422Z","iopub.status.idle":"2023-12-21T11:33:58.435483Z","shell.execute_reply.started":"2023-12-21T11:33:58.370384Z","shell.execute_reply":"2023-12-21T11:33:58.434105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt_train.signal_to_noise.describe()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:33:58.437268Z","iopub.execute_input":"2023-12-21T11:33:58.4384Z","iopub.status.idle":"2023-12-21T11:33:58.515402Z","shell.execute_reply.started":"2023-12-21T11:33:58.438363Z","shell.execute_reply":"2023-12-21T11:33:58.514077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt_train.SN_filter.describe()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:33:58.516883Z","iopub.execute_input":"2023-12-21T11:33:58.517347Z","iopub.status.idle":"2023-12-21T11:33:58.558658Z","shell.execute_reply.started":"2023-12-21T11:33:58.517315Z","shell.execute_reply":"2023-12-21T11:33:58.557317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking number of columns NaN in reactivity and reactivity_error \nfloat_columns = opt_train.select_dtypes(include=['float'])\n\n# Columns that are NaN\nnum_empty_cols= 0\ncols_having_values=0\n\n\n# for col in float_columns.drop('signal_to_noise', axis=1):\nfor col in float_columns:\n    if float_columns[col].notna().sum() == 0:\n        num_empty_cols+=1\n    else:\n        cols_having_values+=1\n        \nprint(f\"Number of Columns with only NaN values: {num_empty_cols} of 412 columns\\n\")\nprint(f\"Number of Columns with values: {cols_having_values} of 412 columns\")","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:33:58.560227Z","iopub.execute_input":"2023-12-21T11:33:58.560594Z","iopub.status.idle":"2023-12-21T11:34:02.078887Z","shell.execute_reply.started":"2023-12-21T11:33:58.560562Z","shell.execute_reply":"2023-12-21T11:34:02.077392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del float_columns\ngc.collect()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:34:02.081014Z","iopub.execute_input":"2023-12-21T11:34:02.081808Z","iopub.status.idle":"2023-12-21T11:34:02.221914Z","shell.execute_reply.started":"2023-12-21T11:34:02.081757Z","shell.execute_reply":"2023-12-21T11:34:02.220566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Wrangling","metadata":{}},{"cell_type":"code","source":"def wrangle(df):\n    \n    # Drop duplicate\n    df= df.drop_duplicates(subset=[\"sequence_id\", \"experiment_type\"])\n    \n    # Drop rows based on SN Filter\n    df= df.loc[df.SN_filter == 1]\n    \n    # Drop the columns \n    df= df.drop(columns=[\"reads\", \"signal_to_noise\",\"SN_filter\"], axis=1)\n    df= df.drop(columns=[col for col in df.columns if \"_error_\" in col], axis=1) \n    \n    # Set categories for categorical columns\n    for col in df.select_dtypes(include=\"category\"):\n        df[col] = df[col].cat.add_categories([0])\n        \n    # Fill NaN value for reactivity & error\n    df= df[7:].fillna(0)\n    \n    return df","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:34:02.223612Z","iopub.execute_input":"2023-12-21T11:34:02.224066Z","iopub.status.idle":"2023-12-21T11:34:02.236306Z","shell.execute_reply.started":"2023-12-21T11:34:02.224015Z","shell.execute_reply":"2023-12-21T11:34:02.234931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_feat=  wrangle(opt_train)\ntrain_feat.head()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:34:02.238263Z","iopub.execute_input":"2023-12-21T11:34:02.238833Z","iopub.status.idle":"2023-12-21T11:34:11.640407Z","shell.execute_reply.started":"2023-12-21T11:34:02.238801Z","shell.execute_reply":"2023-12-21T11:34:11.639076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_feat.shape","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:34:11.64223Z","iopub.execute_input":"2023-12-21T11:34:11.642559Z","iopub.status.idle":"2023-12-21T11:34:11.649331Z","shell.execute_reply.started":"2023-12-21T11:34:11.642531Z","shell.execute_reply":"2023-12-21T11:34:11.648171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del opt_train\ngc.collect()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:34:11.651231Z","iopub.execute_input":"2023-12-21T11:34:11.652447Z","iopub.status.idle":"2023-12-21T11:34:11.765178Z","shell.execute_reply.started":"2023-12-21T11:34:11.652374Z","shell.execute_reply":"2023-12-21T11:34:11.764105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Extraction and Engineering\nUisng just the sequence of the training column won't suffice, so to enrich dataset I will be using the:\n\n- Bpps Thank to [JOCELYN DUMLAO](https://www.kaggle.com/jocelyndumlaohttps://www.kaggle.com/jocelyndumlao)\n- Mean of Bpps\n<!-- - 3D Coords -->\n<!-- - Sequence lib -->\n<!-- - forming OpenKnots and the probabity using metadata -->\n- Probability codons \n- Mean of probability of codons\n<!-- - propbability of forming 2D and 3D structures -->\n- sequence length\n- Mean reactivity\n- secondary structure and its' count [UMAR IGAN](https://www.kaggle.com/code/umar47/rna-folding-reduce-memory-add-features-seq2seq?scriptVersionId=147271807&cellId=31)\n- Adjacent Guanines count\n\n\nto get features for to enrich the dataset.","metadata":{}},{"cell_type":"markdown","source":"### sequence lenght","metadata":{}},{"cell_type":"code","source":"# lenght of sequence to a column\ntrain_feat[\"sequnece_len\"]= train_feat.sequence.astype(str).apply(len)\nopt_test[\"sequnece_len\"]= opt_test.sequence.apply(len)\n\ntrain_feat","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:34:11.766737Z","iopub.execute_input":"2023-12-21T11:34:11.76737Z","iopub.status.idle":"2023-12-21T11:34:16.21368Z","shell.execute_reply.started":"2023-12-21T11:34:11.767334Z","shell.execute_reply":"2023-12-21T11:34:16.212722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt_test.info()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:34:16.215452Z","iopub.execute_input":"2023-12-21T11:34:16.216413Z","iopub.status.idle":"2023-12-21T11:34:16.529425Z","shell.execute_reply.started":"2023-12-21T11:34:16.216362Z","shell.execute_reply":"2023-12-21T11:34:16.528173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get column names of reactivity and reactivity_error\nreactivity_cols= train_feat.columns[train_feat.columns.str.startswith('reactivity_0')]\nreactivity_err_cols= train_feat.columns[train_feat.columns.str.startswith('reactivity_err_0')]\n\nreactivity_cols","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:34:16.531347Z","iopub.execute_input":"2023-12-21T11:34:16.531714Z","iopub.status.idle":"2023-12-21T11:34:16.542303Z","shell.execute_reply.started":"2023-12-21T11:34:16.531681Z","shell.execute_reply":"2023-12-21T11:34:16.541097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### mean reactivity","metadata":{}},{"cell_type":"code","source":"# Get the mean of reactivity columns \ntrain_feat[\"react_mean\"]= train_feat[reactivity_cols].mean(axis=1)\ntrain_feat","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-21T11:34:16.544633Z","iopub.execute_input":"2023-12-21T11:34:16.545036Z","iopub.status.idle":"2023-12-21T11:34:17.359331Z","shell.execute_reply.started":"2023-12-21T11:34:16.545004Z","shell.execute_reply":"2023-12-21T11:34:17.357992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Secondary features: \ndot_brackets notation, Count of bracket notation, BP_matrix, Mean_Bpps, paired and unpair vector, free energy","metadata":{}},{"cell_type":"code","source":"def seq_feat(sequence):\n    \"\"\"Get the secondary features for an RNA sequence, \n    derived using arnie and eternafold packages\n    \n    Parameters\n    ----------\n    sequence: str\n        sequence of bases for an RNA\n    \n    Returns\n    -------\n    features: dictionary\n        secondary features of sequence\n    \"\"\"\n    # Get dot_bracket, free_energy, basepair matrix, paired and unpaired vector.\n    mfe_structure = mfe(sequence, package='eternafold')\n    energy= free_energy(sequence, package='eternafold')\n    bp_matrix = bpps(sequence, package='eternafold')\n    p_unp_vec = 1 - np.sum(bp_matrix, axis=0)\n    features= {\n        \"mfe_structure\":mfe_structure, \n        \"free_energy\":energy, \n        \"bp_matrix\":bp_matrix, \n        \"p_unp_vec\": p_unp_vec\n    }\n    \n    return features\n\n\ndef process_data_in_batches(data, batch_size, name):\n    \"\"\"Process large RNA sequence data in batches\n        \n    Parameters\n    ----------\n    data: str\n        List of RNA sequence data\n    \n    batch_size: int\n        size or number of rows for each batch\n    \n    name: str\n        name for processed dataset\n    \n    Returns\n    -------\n        creates csv files for each processed batch\n    \"\"\"\n    total_count = len(data)\n    chunks = (total_count - 1) // batch_size + 1\n    last_row = None\n    \n    # Train dataset Secondary structure, Base pair matrix, Free energy, pairing vector\n    for i in range(chunks):\n        batch = data[i * batch_size: (i + 1) * batch_size]\n        list_feat= [seq_feat(seq) for seq in batch]\n        \n        filename = f'{name}_sec_struc_{i + 1}.csv'\n        if os.path.exists(filename):\n            last_row = pd.read_csv(filename).iloc[-1].tolist()\n        else: \n            with open(filename, 'w') as f:\n                df= pd.DataFrame(list_feat)\n                # if last_row is not None:\n                    # df.iloc[0] = last_row\n                df.to_csv(f, header=True, index=True) \n                last_row = df.iloc[-1].tolist()\n        \n        # Release unreferenced memory\n                del df\n                gc.collect()\n        del batch, list_feat\n        gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the Secondary features for train and test datasets\n# process_data_in_batches(train_feat.sequence[0:], 50000, \"train\")\n\n# process_data_in_batches(opt_test.sequence[0:], 50000, \"test\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# concatenating csv files into a csv file for test and training data\n\ndef csv_concat(file_path, name):\n    \"\"\" Combine all the csv files into one file\n    \n    Parameter\n    ---------\n    file_path: str\n        path to the csv files\n    \n    name: str\n        name of combined csv file\n    \n    \n    Returns\n    -------\n    combined csv file\n    \n    \"\"\"\n\n    # Create a list of CSV files  to append\n    file_path = file_path\n    file_list = os.listdir(file_path)\n    extract_numeric_part = lambda x: int(x.split('_')[3].split('.')[0])\n    sorted_file_list = sorted(file_list, key=extract_numeric_part)\n\n    # Read each CSV file into a DataFrame\n    combined_csv = pd.concat([pd.read_csv(f\"{file_path}/{f}\") for f in sorted_file_list], ignore_index=True)\n\n    # Export the combined DataFrame to a single CSV file\n    combined_csv.to_csv(f\"features_data/{name}.csv\", index=False)\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# download the features data for test and trian\n\n# !gsutil -m cp \\\n# !  \"gs://kaggle-competition-402916-eu-notebooks/europe-west2-a/instance-20231122-222833/Kaggle-Competition----Stanford-Ribonanza-RNA-Folding/features_data/combined_features/combine_test.csv\" \\\n# !  \"gs://kaggle-competition-402916-eu-notebooks/europe-west2-a/instance-20231122-222833/Kaggle-Competition----Stanford-Ribonanza-RNA-Folding/features_data/combined_features/combine_train.csv\" \\\n\n\n# ! wget https://storage.cloud.google.com/kaggle-competition-402916-eu-notebooks/europe-west2-a/instance-20231122-222833/Kaggle-Competition----Stanford-Ribonanza-RNA-Folding/features_data/combined_features/combine_test.csv?_ga=2.10857908.-1088134625.1698079045\n# ! wget https://storage.cloud.google.com/kaggle-competition-402916-eu-notebooks/europe-west2-a/instance-20231122-222833/Kaggle-Competition----Stanford-Ribonanza-RNA-Folding/features_data/combined_features/combine_train.csv?_ga=2.10857908.-1088134625.1698079045    ","metadata":{"execution":{"iopub.status.busy":"2024-03-07T16:01:49.467052Z","iopub.execute_input":"2024-03-07T16:01:49.467707Z","iopub.status.idle":"2024-03-07T16:01:53.946966Z","shell.execute_reply.started":"2024-03-07T16:01:49.467637Z","shell.execute_reply":"2024-03-07T16:01:53.94541Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"ServiceException: 401 Anonymous caller does not have storage.objects.list access to the Google Cloud Storage bucket. Permission 'storage.objects.list' denied on resource (or it may not exist).\n","output_type":"stream"}]},{"cell_type":"code","source":"csv_concat(\"train_features\", \"combine_train\")\n\ncombine_train_features= pd.read_csv(\"combine_train.csv\")\ncheck.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_concat(\"test_features\", \"combine_test\")\n\ncombine_test_features= pd.read_csv(\"combine_test.csv\")\ncheck.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import structure and bpps to data\n\ntrain_struc_bpps= pd.read_csv(\"train_struc_bpps.csv\")\ntest_struc_bpps= pd.read_csv(\"test_struc_bpps.csv\")\n\nprint(f\"train extracted features shape: {test_struc_bpps.shape}\\ntest extracted features shape {\"test_struc_bpps\"}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate mean BPPs\n\ntrain_struc_bpps[\"avg_bpps\"]= train_seq_bpp.mean(axis=1)\ntest_struc_bpps[\"avg_bpps\"] = test_seq_bpp.mean(axis=1)\n\n\n# print(f\"Train dataset shape: {train_struc_bpps}\")\n# print(f\"Test dataset shape: {test_struc_bpps}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-13T12:07:05.415849Z","iopub.status.idle":"2023-12-13T12:07:05.416764Z","shell.execute_reply.started":"2023-12-13T12:07:05.416523Z","shell.execute_reply":"2023-12-13T12:07:05.416543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to count parentheses\ndef count_parentheses(structure_string):\n    count = structure_string.count(\")\")\n    return count\n\n# Apply the function to the DataFrame column\n\ntq.pandas()\ntrain_struc_bpps['parentheses_counts'] = train_struc_bpps['sec_structure'].astype(str).apply(count_parentheses)\ntest_struc_bpps['parentheses_counts'] = test_struc_bpps['sec_structure'].astype(str).apply(count_parentheses)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T12:07:05.417782Z","iopub.status.idle":"2023-12-13T12:07:05.418527Z","shell.execute_reply.started":"2023-12-13T12:07:05.418316Z","shell.execute_reply":"2023-12-13T12:07:05.418337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### codon features\ncodon count, cps of sequence, codon probability","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n\ndef codons_feats(seq):\n    codons = Counter(seq[i:i+3] for i in range(0, len(seq), 3))\n    pairs = Counter(seq[i:i+6] for i in range(0, len(seq)-1, 3))\n    cps = 0\n    for pair in pairs:\n        if codons[pair[:3]] == 0 or codons[pair[3:]] == 0:\n            continue\n        cps += pairs[pair]/(codons[pair[:3]]*codons[pair[3:]])\n    return {'codons': codons, 'pairs': pairs, 'cps': cps}","metadata":{"execution":{"iopub.status.busy":"2023-12-13T12:07:05.419666Z","iopub.status.idle":"2023-12-13T12:07:05.420427Z","shell.execute_reply.started":"2023-12-13T12:07:05.420223Z","shell.execute_reply":"2023-12-13T12:07:05.420243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the codons, pairs, cps for train sequences\n# codon_feat= []\n\n# for seq in train_feat.sequence:\n#     codon_feat.append(codons_feats(seq))\n\n# # codon_feat= pd.DataFrame(train_feat.sequence.iloc[5:10].apply(codons_feats), columns= [\"codons\", \"pairs\", \"cps\"])\n# codon_feat= pd.DataFrame(codon_feat, columns=[\"codons\", \"pairs\", \"cps\"])\n# codon_feat.to_csv(\"train_codon_feat.csv\")\n\n# codon_feat.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-13T12:07:05.421731Z","iopub.status.idle":"2023-12-13T12:07:05.422221Z","shell.execute_reply.started":"2023-12-13T12:07:05.422063Z","shell.execute_reply":"2023-12-13T12:07:05.422079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the codons, pairs, cps for test sequences\n# codon_feat= []\n\n# for seq in opt_test.sequence:\n#     codon_feat.append(codons_feats(seq))\n\n# # codon_feat= pd.DataFrame(train_feat.sequence.iloc[5:10].apply(codons_feats), columns= [\"codons\", \"pairs\", \"cps\"])\n# codon_feat= pd.DataFrame(codon_feat, columns=[\"codons\", \"pairs\", \"cps\"])\n# codon_feat.to_csv(\"test_codon_feat.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-13T12:07:05.423061Z","iopub.status.idle":"2023-12-13T12:07:05.423964Z","shell.execute_reply.started":"2023-12-13T12:07:05.423642Z","shell.execute_reply":"2023-12-13T12:07:05.423658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define functionto calculate codon probabiltiy\ndef codon_probs_mean(seq):\n#     probs = seq.apply(RNA.codon_prob)\n    probs = [RNA.codon_prob(seq) for s in seq]\n    mean_probs= sum(probs.values()) / len(probs)\n    probs_mean= pd.DataFrame({\"probs\":probs, \"mean_probs\": mean_probs})\n    \n    return probs_mean\n\n\ntrain_condon_probs_mean= codon_probs_mean(train_feat.sequence[:10])\ntrain_condon_probs_mean\n# train_condon_probs_mean.to_csv(\"train_condon_probs_mean.csv\")\n\n# test_condon_probs_mean= codon_probs_mean(opt_test.sequence)\n# test_condon_probs_mean.to_csv(\"test_condon_probs_mean.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### count of adjecent guanines in sequence","metadata":{}},{"cell_type":"code","source":"# function to count adjacent guanines in a codon\n\ndef gg_count(seq):\n    \"\"\"\n    Returns:\n    list of adjcent gg or ggg counts for each sequence\n    \"\"\"\n    adj_guanine= []\n    # Count the number of adjacent guanines\n    for s in seq:\n    adj_guanine.append(gg_count = 0)\n    for i in range(len(s) - 1):\n        if s[i:i+2] == \"GG\" or \"GGG\":\n            gg_count += 1\n            \n    return gg_seq_num\n\n\ntrain_struc_bpps[\"adj_guanine\"]= gg_count(train_feat.sequence)\ntest_struc_bpps[\"adj_guanine\"]= gg_count(opt_test.sequence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### concatenate features into datasets","metadata":{}},{"cell_type":"code","source":"# Concatenate All features to one Dataset called features and test_features\n\nfeatures= pd.concat([train_feat,train_struc_bpps, train_condon_probs_mean])\ntest_features= pd.concat([opt_test,test_struc_bpps,test_condon_probs_mean])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_feat\ndel opt_test\ndel train_struc_bpps\ndel test_struc_bpps\ndel train_condon_probs_mean\ndel test_condon_probs_mean\n\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building Model","metadata":{}},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Dense, Conv1D, Flatten, Input, concatenate\n\n# sequence input (assuming one-hot encoded sequences of length 4)\nsequence_input = Input(shape=(None, 4))\nconv1 = Conv1D(64, kernel_size=3, activation='relu')(sequence_input)\nconv2 = Conv1D(32, kernel_size=3, activation='relu')(conv1)\nflat = Flatten()(conv2)\n\n# numerical/categorical input\nnumerical_input = Input(shape=(4,))\ndense1 = Dense(32, activation='relu')(numerical_input)\n\n# concatenate sequence and numerical inputs\nconcat = concatenate([flat, dense1])\n\n# output layer\noutput = Dense(1, activation='sigmoid')(concat)\n\n# create a model\nmodel = Model(inputs=[sequence_input, numerical_input], outputs=output)\n\n# compile model using MAE as a measure of model performance\nmodel.compile(optimizer='adam', loss='mean_absolute_error')\n","metadata":{},"execution_count":null,"outputs":[]}]}